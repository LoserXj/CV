{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scene Recognition with Bag-of-Words](https://www.cc.gatech.edu/~hays/compvision/proj4/)\n",
    "For this project, you will need to report performance for three\n",
    "combinations of features / classifiers. It is suggested you code them in\n",
    "this order, as well:\n",
    "1. Tiny image features and nearest neighbor classifier\n",
    "2. Bag of sift features and nearest neighbor classifier\n",
    "3. Bag of sift features and linear SVM classifier\n",
    "\n",
    "The starter code is initialized to 'placeholder' just so that the starter\n",
    "code does not crash when run unmodified and you can get a preview of how\n",
    "results are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Set up parameters, image paths and category list\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import student_code_12010923 as sc\n",
    "\n",
    "\n",
    "# This is the list of categories / directories to use. The categories are\n",
    "# somewhat sorted by similarity so that the confusion matrix looks more\n",
    "# structured (indoor and then urban and then rural).\n",
    "categories = ['Kitchen', 'Store', 'Bedroom', 'LivingRoom', 'Office', 'Industrial', 'Suburb',\n",
    "              'InsideCity', 'TallBuilding', 'Street', 'Highway', 'OpenCountry', 'Coast',\n",
    "              'Mountain', 'Forest'];\n",
    "# This list of shortened category names is used later for visualization\n",
    "abbr_categories = ['Kit', 'Sto', 'Bed', 'Liv', 'Off', 'Ind', 'Sub',\n",
    "                   'Cty', 'Bld', 'St', 'HW', 'OC', 'Cst',\n",
    "                   'Mnt', 'For'];\n",
    "\n",
    "# Number of training examples per category to use. Max is 100. For\n",
    "# simplicity, we assume this is the number of test cases per category, as\n",
    "# well.\n",
    "num_train_per_cat = 100\n",
    "\n",
    "# This function returns lists containing the file path for each train\n",
    "# and test image, as well as lists with the label of each train and\n",
    "# test image. By default all four of these lists will have 1500 elements\n",
    "# where each element is a string.\n",
    "data_path = osp.join('..', 'data')\n",
    "train_image_paths, test_image_paths, train_labels, test_labels = get_image_paths(data_path,\n",
    "                                                                                 categories,\n",
    "                                                                                 num_train_per_cat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Tiny Image features with Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1a: Represent each image with the Tiny Image feature\n",
    "\n",
    "Each function to construct features should return an N x d numpy array, where N is the number of paths passed to the function and d is the dimensionality of each image representation. See the starter code for each function for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the TINY IMAGE representation for images\n"
     ]
    }
   ],
   "source": [
    "print('Using the TINY IMAGE representation for images')\n",
    "\n",
    "train_image_feats = sc.get_tiny_images(train_image_paths)\n",
    "test_image_feats = sc.get_tiny_images(test_image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1b: Classify each test image by training and using the Nearest Neighbor classifier\n",
    "\n",
    "Each function to classify test features will return an N element list, where N is the number of test cases and each entry is a string indicating the predicted category for each test image. Each entry in 'predicted_categories' must be one of the 15 strings in 'categories', 'train_labels', and 'test_labels'. See the starter code for each function for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NEAREST NEIGHBOR classifier to predict test set categories\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing NEAREST NEIGHBOR classifier to predict test set categories\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m predicted_categories \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnearest_neighbor_classify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_image_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_image_feats\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\30684\\Desktop\\Assignment3\\Assignment3_code\\mycode\\student_code_12010923.py:251\u001b[0m, in \u001b[0;36mnearest_neighbor_classify\u001b[1;34m(train_image_feats, train_labels, test_image_feats, metric)\u001b[0m\n\u001b[0;32m    248\u001b[0m distances \u001b[38;5;241m=\u001b[39m pairwise_distances(test_feats\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), train_image_feats, metric\u001b[38;5;241m=\u001b[39mmetric)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# 找到最近的k个邻居的索引\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m nearest_neighbor_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(distances)[\u001b[38;5;241m0\u001b[39m][:\u001b[43mk\u001b[49m]\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# 根据最近的邻居的标签进行投票\u001b[39;00m\n\u001b[0;32m    254\u001b[0m votes \u001b[38;5;241m=\u001b[39m [train_labels[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m nearest_neighbor_indices]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "print('Using NEAREST NEIGHBOR classifier to predict test set categories')\n",
    "\n",
    "predicted_categories = sc.nearest_neighbor_classify(train_image_feats, train_labels, test_image_feats,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1c: Build a confusion matrix and score the recognition system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You do not need to code anything in this section.)\n",
    "\n",
    "If we wanted to evaluate our recognition method properly we would train\n",
    "and test on many random splits of the data. You are not required to do so\n",
    "for this project.\n",
    "\n",
    "This function will create a confusion matrix and various image\n",
    "thumbnails each time it is called. View the confusion matrix to help interpret\n",
    "your classifier performance. Where is it making mistakes? Are the\n",
    "confusions reasonable?\n",
    "\n",
    "Interpreting your performance with 100 training examples per category:\n",
    "- accuracy  =   0 -> Your code is broken (probably not the classifier's fault! A classifier would have to be amazing to perform this badly).\n",
    "- accuracy ~= .07 -> Your performance is chance. Something is broken or you ran the starter code unchanged.\n",
    "- accuracy ~= .20 -> Rough performance with tiny images and nearest neighbor classifier. Performance goes up a few percentage points with K-NN instead of 1-NN.\n",
    "- accuracy ~= .20 -> Rough performance with tiny images and linear SVM classifier. The linear classifiers will have a lot of trouble trying to separate the classes and may be unstable (e.g. everything classified to one category)\n",
    "- accuracy ~= .50 -> Rough performance with bag of SIFT and nearest neighbor classifier. Can reach .60 with K-NN and different distance metrics.\n",
    "- accuracy ~= .60 -> You've gotten things roughly correct with bag of SIFT and a linear SVM classifier.\n",
    "- accuracy >= .70 -> You've also tuned your parameters well. E.g. number of clusters, SVM regularization, number of patches sampled when building vocabulary, size and step for dense SIFT features.\n",
    "- accuracy >= .80 -> You've added in spatial information somehow or you've added additional, complementary image features. This represents state of the art in Lazebnik et al 2006.\n",
    "- accuracy >= .85 -> You've done extremely well. This is the state of the art in the 2010 SUN database paper from fusing many  features. Don't trust this number unless you actually measure many random splits.\n",
    "- accuracy >= .90 -> You used modern deep features trained on much larger image databases.\n",
    "- accuracy >= .96 -> You can beat a human at this task. This isn't a realistic number. Some accuracy calculation is broken or your classifier is cheating and seeing the test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(train_image_paths, test_image_paths, train_labels, test_labels, categories, abbr_categories,\n",
    "             predicted_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Bag of SIFT features with Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2a: Represent each image with the Bag of SIFT feature\n",
    "\n",
    "To create a new vocabulary, make sure `vocab_filename` is different than the old vocabulary, or delete the old one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using the BAG-OF-SIFT representation for images')\n",
    "\n",
    "vocab_filename = 'vocab.pkl'\n",
    "if not osp.isfile(vocab_filename):\n",
    "    # Construct the vocabulary\n",
    "    print('No existing visual word vocabulary found. Computing one from training images')\n",
    "    vocab_size = 200  # Larger values will work better (to a point) but be slower to compute\n",
    "    vocab = sc.build_vocabulary(train_image_paths, vocab_size)\n",
    "    with open(vocab_filename, 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "        print('{:s} saved'.format(vocab_filename))\n",
    "\n",
    "train_image_feats = sc.get_bags_of_sifts(train_image_paths, vocab_filename)\n",
    "test_image_feats = sc.get_bags_of_sifts(test_image_paths, vocab_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2b: Classify each test image by training and using the Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using NEAREST NEIGHBOR classifier to predict test set categories')\n",
    "predicted_categories = sc.nearest_neighbor_classify(train_image_feats, train_labels, test_image_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2c: Build a confusion matrix and score the recognition system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(train_image_paths, test_image_paths, train_labels, test_labels, categories, abbr_categories,\n",
    "             predicted_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Bag of SIFT features and SVM classifier\n",
    "We will reuse the bag of SIFT features from Section 2a.\n",
    "\n",
    "The difference is that this time we will classify them with a support vector machine (SVM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3a: Classify each test image by training and using the SVM classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using SVM classifier to predict test set categories')\n",
    "predicted_categories = sc.svm_classify(train_image_feats, train_labels, test_image_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3b: Build a confusion matrix and score the recognition system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(train_image_paths, test_image_paths, train_labels, test_labels, categories, abbr_categories,\n",
    "             predicted_categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
